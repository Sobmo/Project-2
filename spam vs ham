"""Project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pd9YfUdXmiaU5gxfczZdmK5kFcM89F0W
"""

!pip install --upgrade tensorflow

from __future__ import print_function
import pandas as pd
pd.__version__

import os
os.getcwd()

#Mouting the drive to load a simple dataset stored on the google drive
from google.colab import drive
drive.mount('/content/gdrive')

#Loading a dataset into a dataframe
spam_dataset_dataframe = pd.read_csv("/content/gdrive/My Drive/DSProject/spam.csv", sep = ',')
print('Dataset Loaded...')
spam_dataset_dataframe.describe()

#Access to row 0 to 10
spam_dataset_dataframe.iloc[0:10]



#Plot per feature histogram. figsize = (width, height)
spam_dataset_dataframe.hist(bins=25,figsize=(25,20))

import numpy as np

#Define a function to create a training and test set.
#Takes dataframe and split ratio as input and outputs train and test datasets (dataframes)
def split_train_test(data,test_ratio):
  np.random.seed(20) 
  shuffled_indices = np.random.permutation(len(data))
  test_set_size = int(len(data)*test_ratio)
  test_indices = shuffled_indices[:test_set_size]
  train_indices = shuffled_indices[test_set_size:]
  return data.iloc[train_indices], data.iloc[test_indices]

from sklearn.model_selection import train_test_split

spam_training_set, spam_test_set = train_test_split(spam_dataset_dataframe, test_size=0.5,random_state=20)
spam_dataset_dataframe.keys()
spam_test_set.head()

spam_training_data, spam_training_target = spam_training_set[["make","address","all","3d","our","over","remove","internet","order","mail","bracket","bang","dollar","pound","cap_avg","cap_long","cap_total"]], spam_training_set["Class"]
spam_test_data, spam_test_target = spam_test_set[["make","address","all","3d","our","over","remove","internet","order","mail","bracket","bang","dollar","pound","cap_avg","cap_long","cap_total"]], spam_test_set["Class"]
spam_training_data.head()

len(spam_training_set)

len(spam_test_set)

#Create training and test datasets for spam data
spam_training_set, spam_test_set = split_train_test(spam_dataset_dataframe, 0.7826)
#spam_test_set.head()
#spam_test_set.info()

from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import AdaBoostClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
#clf = RandomForestClassifier(n_estimators=1000)
#clf = DecisionTreeClassifier(criterion = "entropy")
#clf_dt = DecisionTreeClassifier(criterion = "entropy")
#clf = KNeighborsClassifier(n_neighbors=7)
#clf = AdaBoostClassifier(n_estimators = 200)
LRI = LogisticRegression()
#clf_lr = LogisticRegression()
#clf_gnb = GaussianNB()
clf = AdaBoostClassifier(n_estimators = 200,base_estimator=LRI)
#eclf = VotingClassifier(estimators = [('DT', clf_dt),('LR',clf_lr),('GNB',clf_gnb)], voting ='hard')
clf.fit(spam_training_data,spam_training_target)
#eclf.fit(spam_training_data,spam_training_target)

spam_test_target_predict=clf.predict(spam_test_data)
#confusion_matrix(spam_test_target,spam_test_target_predict)
#classification_report(spam_test_target,spam_test_target_predict)
accuracy_score(spam_test_target,spam_test_target_predict)
